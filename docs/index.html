<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta name="keywords" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="google-site-verification" content="YyDLtcGtegAATTYnhSXnvL6klnX3Bk00jCY9dZQxCTo" />
    <title>Object-Centric Concept-Bottlenecks</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/aiml_logo.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/fireworks.js"></script>

</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://ml-research.github.io">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>

                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="https://ml-research.github.io/NeuralConceptBinder/">
                            Neural Concept Binder
                        </a>
                    </div>
                </div>
            </div>

        </div>
    </nav>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Object-Centric Concept-Bottlenecks
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://www.ml.informatik.tu-darmstadt.de/people/dsteinmann/index.html"
                                    target="_blank">David Steinmann</a><sup>1,2</sup>,</span>
                            <span class="author-block">
                                <a href="https://wolfstam.github.io/" target="_blank">Wolfgang
                                    Stammer</a><sup>1,2</sup>,</span>
                            <span class="author-block">
                                <a href="https://ml-research.github.io/people/awuest/index.html" target="_blank">Antonia
                                    W&uuml;st</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://ml-research.github.io/people/kkersting/" target="_blank">Kristian
                                    Kersting</a><sup>1,2,3,4</sup>,
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>AI/ML Lab at TU Darmstadt,</span>
                            <span class="author-block"><sup>2</sup>Hessian Center for AI (hessian.AI),</span>
                            <span class="author-block"><sup>3</sup>German Research Center for AI (DFKI)</span>
                            <span class="author-block"><sup>4</sup>Centre for Cognitive Science at TU Darmstadt,</span>
                            <br />
                            <!-- <span class="author-block"><sup>*</sup>Equal contribution</span> -->
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2505.24492"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/DavSte13/Object-Centric-Concept-Bottlenecks"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="content has-text-centered">
                    <img src="./static/images/hero.png" class="motivation-image" alt="Motivation for object-centric representations" />

                    <h3 class="subtitle has-text-centered">
                        Our paper introduces Object-Centric Concept Bottlenecks (OCB), a framework that integrates object-centricity into concept-based models to improve both performance and interpretability in complex vision tasks.
                    </h3>
                </div>
            </div>
        </div>
    </section>




    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <!-- Abstract. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                                Developing high-performing, yet interpretable models remains a critical challenge
                                in modern AI. Concept-based models (CBMs) attempt to address this by extracting
                                human-understandable concepts from a global encoding (e.g., image encoding)
                                and then applying a linear classifier on the resulting concept activations, enabling
                                transparent decision-making. However, their reliance on holistic image encodings
                                limits their expressiveness in object-centric real-world settings and thus hinders
                                their ability to solve complex vision tasks beyond single-label classification. To
                                tackle these challenges, we introduce Object-Centric Concept Bottlenecks (OCB),
                                a framework that combines the strengths of CBMs and pre-trained object-centric
                                foundation models, boosting performance and interpretability. We evaluate OCB on
                                complex image datasets and conduct a comprehensive ablation study to analyze key
                                components of the framework, such as strategies for aggregating object-concept
                                encodings. The results show that OCB outperforms traditional CBMs and allows
                                one to make interpretable decisions for complex visual tasks.
                            </p>
                        </div>
                    </div>
                </div>
                <!--/ Abstract. -->

            </div>
        </div>
    </section>


    <section class="section">

        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Combining Image-level and Object-level Concepts</h2>

                    <p>
                        The proposed Object-Centric Concept Bottleneck (OCB) framework enables interpretable, object-aware reasoning for complex visual tasks via the following steps:
                        (I) An object proposal module identifies and refines object candidates within an image. 
                        (II) A concept discovery module encodes the entire image and its object crops into human-understandable concept activations. 
                        (III) These activations are aggregated and passed to a simple, interpretable predictor to generate the final output.  <br />
                    </p>


                    <div class="content has-text-justified">
                        <p>
                        </p>
                        <div class="hero-body">
                            <img src="./static/images/method.png" class="interpretability-image"
                                alt="Description of the OCB framework" />
                        </div>
                    </div>
                </div>
            </div>

    </section>


    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <!-- Task 2. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">More Fine-grained and Modular Concept Space</h2>
                        <div class="content has-text-justified">

                            <p>
                                Object-centric concept representations allow for a more fine-grained and modular concept space. 
                                They include previously undiscovered concepts or provide detailed information about object counts.
                                It is even possible to trace concept activations and concept relevance back to the objects from which they come.
                            </p>

                            <img src="./static/images/concept_space.png" class="interpretability-image"
                                alt="Examples of detected concepts." />
                        </div>
                    </div>
                </div>
                <!--/ Task 2. -->
            </div>
        </div>
    </section>

    <section class="section">

        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">COCOLogic</h2>

                    <p>
                        We introduce COCOLogic, a benchmark derived from the MSCOCO dataset that evaluates a model’s ability to perform structured visual reasoning in a single-label classification setting. Unlike standard object recognition tasks, COCOLogic requires classification based on logical combinations of object categories, including conjunctions, disjunctions, negations, and counting constraints.

                        Each image is assigned to exactly one of ten mutually exclusive classes, ensuring unambiguous labeling. These classes are defined by semantically meaningful logical rules (e.g., “occupied interior” requires a chair or couch and at least one person, while “empty seat” requires the same furniture but no person). Images that do not satisfy exactly one rule are excluded.

                        Scripts to generate COCOLogic from the MSCOCO dataset can be found in our GitHub repository. 
                    <div class="content has-text-justified">
                        <p>
                        </p>
                        <div class="hero-body">

                            <img src="./static/images/cocologic.png" class="interpretability-image"
                                alt="Overview of the COCOLogic dataset" />
                        </div>
                    </div>

                </div>
            </div>
            <br />
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{steinmann2025object,
                title={Object Centric Concept Bottlenecks},
                author={Steinmann, David and Stammer, Wolfgang and W{\"u}st, Antonia and Kersting, Kristian},
                journal={Advances in Neural Information Processing Systems (NeurIPS)},
                year={2025}
                }
      </code></pre>
        </div>
    </section>

    <div id="modal" class="modal">
        <div class="modal-content">
            <span class="close">&times;</span>
            <p id="modal-message"></p>
            <canvas id="fireworks-canvas"></canvas>
        </div>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="https://arxiv.org/abs/2505.24492">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/DavSte13/Object-Centric-Concept-Bottlenecks" class="external-link"
                    disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This work was supported by the ”ML2MT” project from the Volkswagen Stiftung, the Priority Program (SPP) 2422 in the subproject “Optimization of active surface design of high-speed progressive tools using machine and deep learning algorithms“ funded by the German Research Foundation (DFG) and supported by the DFG under Germany’s Excellence Strategy (EXC 3066/1 “The Adaptive Mind”, Project No. 533717223).
It has further benefited from the HMWK projects ”The Third Wave of Artificial Intelligence - 3AI”, and Hessian.AI, the Hessian research priority program LOEWE within the project WhiteBox, the EU-funded “TANGO” project (EU Horizon 2023, GA No 57100431), and from early stages of the Cluster of Excellence "Reasonable AI" funded by the German Research Foundation (DFG) under Germany’s Excellence Strategy— EXC-3057; funding will begin in 2026.
                        </p>
                        <p>The website template is based on the source code of <a
                                href="https://github.com/nerfies/nerfies.github.io">this
                                website</a>. </p>
                        <p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>